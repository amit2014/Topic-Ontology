{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TF-IDF</h1>\n",
    "Author: Tristan\n",
    "\n",
    "You can learn about TF-IDF here:\n",
    "https://en.wikipedia.org/wiki/Tfâ€“idf\n",
    "In brief, it is a way to choose the weight of different terms in a corpus.\n",
    "\n",
    "It is *not* a way to reduce the number of terms.\n",
    "Terms can be reduced afterwards using Semantic Analysis (for which there are multiple methods)\n",
    "https://en.wikipedia.org/wiki/Semantic_analysis_(machine_learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import *\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>links</th>\n",
       "      <th>categories</th>\n",
       "      <th>process</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Art</td>\n",
       "      <td>[[File:Chemin montant dans les hautes herbes -...</td>\n",
       "      <td>[renoir, senses, bowl, creativity, drawing, pa...</td>\n",
       "      <td>[Art, Non-verbal communication, Basic English ...</td>\n",
       "      <td>art activ creation peopl import attract human ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>Abbreviation</td>\n",
       "      <td>An '''abbreviation''' is a shorter way to writ...</td>\n",
       "      <td>[english language, apostrophe, period (punctua...</td>\n",
       "      <td>[Linguistics]</td>\n",
       "      <td>abbrevi shorter way write word phrase peopl us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>Astronomy</td>\n",
       "      <td>[[File:Atlas Coelestis-1.jpg|thumb|280px|18th ...</td>\n",
       "      <td>[natural science, atmosphere of earth, astrono...</td>\n",
       "      <td>[Astronomy]</td>\n",
       "      <td>astronomi natur scienc studi everyth outsid at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>Browser</td>\n",
       "      <td>{{Distinguish|Web browser}}\\n[[Image:Giraffe f...</td>\n",
       "      <td>[herbivorous, mammal, leaves, shrub, grass, gr...</td>\n",
       "      <td>[Ecology, Zoology]</td>\n",
       "      <td>browser anim usual herbivor mammal eat leav sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>Bubonic plague</td>\n",
       "      <td>{{Infobox disease\\n| Name            = Bubonic...</td>\n",
       "      <td>[lymphatic system, plague, bacterium, yersinia...</td>\n",
       "      <td>[Plague, Pulmonology]</td>\n",
       "      <td>bubon plagu best known form diseas plagu caus ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index           title                                               text  \\\n",
       "0      3             Art  [[File:Chemin montant dans les hautes herbes -...   \n",
       "1     19    Abbreviation  An '''abbreviation''' is a shorter way to writ...   \n",
       "2     29       Astronomy  [[File:Atlas Coelestis-1.jpg|thumb|280px|18th ...   \n",
       "3     50         Browser  {{Distinguish|Web browser}}\\n[[Image:Giraffe f...   \n",
       "4     63  Bubonic plague  {{Infobox disease\\n| Name            = Bubonic...   \n",
       "\n",
       "                                               links  \\\n",
       "0  [renoir, senses, bowl, creativity, drawing, pa...   \n",
       "1  [english language, apostrophe, period (punctua...   \n",
       "2  [natural science, atmosphere of earth, astrono...   \n",
       "3  [herbivorous, mammal, leaves, shrub, grass, gr...   \n",
       "4  [lymphatic system, plague, bacterium, yersinia...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  [Art, Non-verbal communication, Basic English ...   \n",
       "1                                      [Linguistics]   \n",
       "2                                        [Astronomy]   \n",
       "3                                 [Ecology, Zoology]   \n",
       "4                              [Plague, Pulmonology]   \n",
       "\n",
       "                                             process  \n",
       "0  art activ creation peopl import attract human ...  \n",
       "1  abbrevi shorter way write word phrase peopl us...  \n",
       "2  astronomi natur scienc studi everyth outsid at...  \n",
       "3  browser anim usual herbivor mammal eat leav sh...  \n",
       "4  bubon plagu best known form diseas plagu caus ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = nlp.proc_text()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gerd ller born novemb n rdlingen former footbal player play fc bayern nchen germani nation team best striker time still own mani score record career club career start play footbal tsv n rdlingen score season goal play fc bayern nchen first season bayern nchen score match goal till score bundesliga match score goal record still exist till play us profession leagu ford lauderdal striker smith brother loung intern start intern career octob ankara versu turkey second match versu albania score first four goal nation team member fifa world cup team ten goal best scorer tournament germani european championship ller best scorer tournament germani fifa world cup score second goal victori netherland tournament resign team record ller score goal match germani best scorer team miroslav klose broke record two world cup score goal record broken ronaldo world cup honor titl bayern munich intercontinent cup european champion cup european cup winner cup bundesliga german cup regionalliga intern world cup third place european championship person honour european footbal year german footbal year vote best player year bundesliga european top scorer german top scorer world cup top scorer european championship top scorer european cup top scorer world footbal greatest goalscor time award name fifa club career statist colspan colspan intern career statist websit portrait gerd ller fifa com statist ller match goal rsssf com refer'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['process'][2627]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer = \"word\", max_df=1.0, min_df=.03)\n",
    "#max_df is the fraction of documents that must have a word before it is ignored.\n",
    "#min_df is the fraction of documents that must have a word for it to be considered.\n",
    "#norm=\"l2\" normalizes each document vector to a (pythagorean) length of 1.\n",
    "clean_text = data[\"process\"]\n",
    "weighted_words = vectorizer.fit_transform(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#also get the bag of words without weighting for comparison\n",
    "vectorizer2 = CountVectorizer(analyzer = \"word\",min_df=.03)\n",
    "unweighted_words = vectorizer2.fit_transform(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 394)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unweighted_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Want a function to list words alongside their frequency\n",
    "def get_word_frequency(sparse_matrix,doc,word_list):\n",
    "    #find number of distinct words in given document\n",
    "    num_words = sparse_matrix[doc,:].getnnz()\n",
    "    #initialize DataFrame\n",
    "    word_frequency = pd.DataFrame(index=range(num_words), columns=['word','frequency'])\n",
    "    #convert to another kind of sparse matrix\n",
    "    cx = scipy.sparse.coo_matrix(sparse_matrix[doc,:])\n",
    "    #Loop over nonzero elements in the sparse matrix\n",
    "    #with i = column number, j = weight, and k being the appropriate row of the DataFrame\n",
    "    for i,j,k in zip(cx.col,cx.data,range(num_words)):\n",
    "        word_frequency['word'][k] = word_list[i]\n",
    "        word_frequency['frequency'][k] = j\n",
    "        \n",
    "    #Finally, sort the DataFrame\n",
    "    word_frequency.sort_values('frequency',inplace=True,ascending=False)\n",
    "    return word_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th document, before TF-IDF:\n",
      "        word frequency\n",
      "71     star        32\n",
      "4       use        18\n",
      "73     time        12\n",
      "72  univers        12\n",
      "70    studi        12\n",
      "52    chang        10\n",
      "14     bodi         9\n",
      "9      make         8\n",
      "95   around         8\n",
      "42     look         8\n",
      "After TF-IDF:\n",
      "         word frequency\n",
      "84      star  0.593086\n",
      "85     studi  0.221979\n",
      "151      use  0.220351\n",
      "83   univers   0.20068\n",
      "141     bodi  0.176538\n",
      "103    chang  0.170967\n",
      "113     look  0.156743\n",
      "82      time  0.156632\n",
      "97      come  0.139222\n",
      "98    period  0.138106\n"
     ]
    }
   ],
   "source": [
    "doc_number = 2\n",
    "test_freq = get_word_frequency(unweighted_words,doc_number,vectorizer2.get_feature_names())\n",
    "test_weight = get_word_frequency(weighted_words,doc_number,vectorizer.get_feature_names())\n",
    "print(str(doc_number) + \"th document, before TF-IDF:\\n\",test_freq[0:10])\n",
    "print(\"After TF-IDF:\\n\",test_weight[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving data\n",
    "\n",
    "Although the purpose of this notebook was originally to implement TF-IDF, it offers a most convenient point to save data.\n",
    "\n",
    "About this data: We included a random selection of 10k articles from simple wikipedia.  The document-term matrix is unweighted, and only includes the 394 words that occur in at least 3% of articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_pickle(\"processed_10k_articles.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numpy.save(\"document_term_matrix\",unweighted_words,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(vectorizer.get_feature_names()).to_pickle(\"term_list.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "The following code can load the data in its original form.  Note that loading the npy file is a bit tricky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_10k_articles = pd.read_pickle(\"processed_10k_articles.pkl\")\n",
    "document_term_matrix = numpy.reshape(numpy.load(\"document_term_matrix.npy\"),(1))[0]\n",
    "term_list = pd.read_pickle(\"term_list.pkl\")[0].tolist()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

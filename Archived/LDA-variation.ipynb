{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA \n",
    "I am using the LDA package and following their main example [here](https://pypi.python.org/pypi/lda) closely.\n",
    "- The number of topics is set at 20.\n",
    "- with the 0.05 cutoff for vocab (which we are using elsewhere, and 20 topics), the algorithm gives results in the order of a minute (didn't time it.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import *\n",
    "import lda #use pip install lda \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"processed_10k_articles.pkl\")\n",
    "titles = [word for word in data.title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from Tristan's code:\n",
    "#putting the code first \n",
    "#first generate the bag of words.  This has no TF-IDF weighting yet.\n",
    "#Only include words that occur in at least 5% of documents.\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",min_df=0.05) #0.05\n",
    "clean_text = [' '.join( (txt.split())[0: min(500, len(txt.split()))])  for txt in data['process'] ]  #data[\"process\"]\n",
    "unweighted_words = vectorizer.fit_transform(clean_text)\n",
    "terms_matrix = unweighted_words.toarray()\n",
    "vocabulary  = vectorizer.vocabulary_ # the words selected \n",
    "vocab = [w for w in vocabulary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lda.lda.LDA at 0x1136fa4e0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lda.LDA(n_topics=5, n_iter=1500, random_state=1)\n",
    "model.fit(terms_matrix)  # model.fit_transform(X) is also available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1177)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word = model.topic_word_ \n",
    "topic_word.shape # all elements are >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic = model.doc_topic_\n",
    "doc_topic.shape # all elements are >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: top words: territori known begin way collect \n",
      " (article with highest weight: List of Nobel Prize winners by country)\n",
      "Topic 1: top words: reduc lord pass latin britain \n",
      " (article with highest weight: List of rivers of Portugal)\n",
      "Topic 2: top words: join hill latin boston insid \n",
      " (article with highest weight: Hypercholesterolemia)\n",
      "Topic 3: top words: program german troop ii score \n",
      " (article with highest weight: List of awards and nominations received by Bryan Adams)\n",
      "Topic 4: top words: mexico cut code name european \n",
      " (article with highest weight: Ryan Miller)\n"
     ]
    }
   ],
   "source": [
    "# looking at the topics that are produced\n",
    "n_top_words = 5\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    tmp_topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    print('Topic {}: top words: {} \\n (article with highest weight: {})'.format(\\\n",
    "    i, ' '.join(tmp_topic_words), titles[doc_topic[:,i].argmax()]  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Art (top topic: [3 2])\n",
      "Abbreviation (top topic: [1 2])\n",
      "Astronomy (top topic: [0 2])\n",
      "Browser (top topic: [4 2])\n",
      "Bubonic plague (top topic: [0 2])\n",
      "Cooking (top topic: [4 2])\n",
      "Calculus (top topic: [1 2])\n",
      "Coin (top topic: [4 2])\n",
      "Earth science (top topic: [1 2])\n",
      "Everything2 (top topic: [3 2])\n"
     ]
    }
   ],
   "source": [
    "# looking at articles\n",
    "for i in range(10):\n",
    "#     print(\"{} (top topic: {})\".format(titles[i], doc_topic[i].argmax()))\n",
    "     print(\"{} (top topic: {})\".format(titles[i], doc_topic[i].argsort()[-2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 40 most informative words:\n",
      "    mexico, highest-weight topic:  4, lowest-weight topic:2\n",
      "      code, highest-weight topic:  4, lowest-weight topic:2\n",
      "       cut, highest-weight topic:  4, lowest-weight topic:2\n",
      "      name, highest-weight topic:  4, lowest-weight topic:2\n",
      "  european, highest-weight topic:  4, lowest-weight topic:2\n",
      "     reduc, highest-weight topic:  1, lowest-weight topic:2\n",
      "      join, highest-weight topic:  2, lowest-weight topic:4\n",
      "  democrat, highest-weight topic:  4, lowest-weight topic:2\n",
      "      lord, highest-weight topic:  1, lowest-weight topic:2\n",
      "   program, highest-weight topic:  3, lowest-weight topic:0\n",
      "    design, highest-weight topic:  4, lowest-weight topic:2\n",
      "    friend, highest-weight topic:  4, lowest-weight topic:2\n",
      "        ii, highest-weight topic:  4, lowest-weight topic:2\n",
      "       hit, highest-weight topic:  4, lowest-weight topic:2\n",
      "      valu, highest-weight topic:  4, lowest-weight topic:2\n",
      "      pass, highest-weight topic:  4, lowest-weight topic:2\n",
      "     child, highest-weight topic:  4, lowest-weight topic:0\n",
      "    german, highest-weight topic:  3, lowest-weight topic:2\n",
      " territori, highest-weight topic:  0, lowest-weight topic:3\n",
      "     latin, highest-weight topic:  1, lowest-weight topic:4\n",
      "     known, highest-weight topic:  0, lowest-weight topic:2\n",
      "   britain, highest-weight topic:  1, lowest-weight topic:0\n",
      "      move, highest-weight topic:  1, lowest-weight topic:3\n",
      "       hot, highest-weight topic:  1, lowest-weight topic:2\n",
      "      bird, highest-weight topic:  4, lowest-weight topic:2\n",
      "      cast, highest-weight topic:  1, lowest-weight topic:2\n",
      "    spread, highest-weight topic:  3, lowest-weight topic:2\n",
      "     troop, highest-weight topic:  4, lowest-weight topic:2\n",
      "   america, highest-weight topic:  1, lowest-weight topic:2\n",
      "     peter, highest-weight topic:  3, lowest-weight topic:0\n",
      "      titl, highest-weight topic:  1, lowest-weight topic:2\n",
      "     score, highest-weight topic:  3, lowest-weight topic:2\n",
      "   italian, highest-weight topic:  3, lowest-weight topic:2\n",
      "   largest, highest-weight topic:  1, lowest-weight topic:2\n",
      "     civil, highest-weight topic:  4, lowest-weight topic:2\n",
      "   footbal, highest-weight topic:  1, lowest-weight topic:4\n",
      "      race, highest-weight topic:  3, lowest-weight topic:2\n",
      "     escap, highest-weight topic:  1, lowest-weight topic:2\n",
      "     begin, highest-weight topic:  0, lowest-weight topic:3\n",
      "     itali, highest-weight topic:  1, lowest-weight topic:2\n"
     ]
    }
   ],
   "source": [
    "# top 40 most informative words in the vocabulary\n",
    "voc_var = [topic_word[:,i].var() for i in range(topic_word[:,:].shape[1]) ]\n",
    "tophowmany = 40\n",
    "print('top %i most informative words:'%tophowmany)\n",
    "top_informative_words = np.asarray(voc_var).argsort()[::-1][:tophowmany]\n",
    "for i in top_informative_words:\n",
    "    print(\"%10s, highest-weight topic:%3d, lowest-weight topic:%d\"%(vocab[i], topic_word[:,i].argmax(),  topic_word[:,i].argmin() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = pd.read_html('https://en.wikipedia.org/wiki/' + 'Pierre-Simon_Laplace',flavor='bs4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = [word for word in w if w is not np.NaN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 2)\n",
      "(10, 1)\n",
      "(1, 2)\n",
      "(1, 2)\n",
      "(1, 2)\n",
      "(2, 3)\n",
      "(28, 31)\n",
      "(19, 2)\n",
      "(2, 1)\n",
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(w)):\n",
    "     print(w[i].shape)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v t e French Consulate (10 November 1799 – 18 May 1804)'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[6].iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biology is a natural science concerned with the study of life and living organisms, including their structure, function, growth, evolution, distribution, identification and taxonomy. Modern biology is a vast and eclectic field, composed of many branches and subdisciplines. However, despite the broad scope of biology, there are certain general and unifying concepts within it that govern all study and research, consolidating it into single, coherent field. In general, biology recognizes the cell as the basic unit of life, genes as the basic unit of heredity, and evolution as the engine that propels the synthesis and creation of new species. It is also understood today that all the organisms survive by consuming and transforming energy and by regulating their internal environment to maintain a stable and vital condition known as homeostasis.\n",
      "Sub-disciplines of biology are defined by the scale at which organisms are studied, the kinds of organisms studied, and the methods used to study them: biochemistry examines the rudimentary chemistry of life; molecular biology studies the complex interactions among biological molecules; botany studies the biology of plants; cellular biology examines the basic building-block of all life, the cell; physiology examines the physical and chemical functions of tissues, organs, and organ systems of an organism; evolutionary biology examines the processes that produced the diversity of life; and ecology examines how organisms interact in their environment.\n"
     ]
    }
   ],
   "source": [
    "print( wikipedia.summary(\"bilogy\",sentences = 1000) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
